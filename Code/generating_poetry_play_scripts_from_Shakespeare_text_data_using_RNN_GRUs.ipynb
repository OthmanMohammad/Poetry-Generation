{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "generating poetry/play-scripts from Shakespeare text data using RNN - GRUs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0N0ovhqkNXB4"
      },
      "source": [
        "## reference\n",
        "https://www.tensorflow.org/text/tutorials/text_generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uj7_BXWTTwMX"
      },
      "source": [
        "# **Importing libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-syhJflDofa"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pezKmqEpUCD9"
      },
      "source": [
        "# **Download the Shakespeare dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVEVL4enT-gS"
      },
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7l93L4WUIBl"
      },
      "source": [
        "# **Read the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuWTTNlEUFPq",
        "outputId": "b2f26c4b-2af1-4e6d-e73b-824eb5097a2e"
      },
      "source": [
        "# Read, then decode for py2 compat.\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print(f'Length of text: {len(text)} characters')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 1115394 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wj-lIHHUOzo",
        "outputId": "5ec87527-3f35-44e7-86c5-3a323e9cba38"
      },
      "source": [
        "# Take a look at the first 250 characters in text\n",
        "print(text[:250])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDDsxaywUQ_R",
        "outputId": "0f42f985-b72b-4517-90dd-a9ca06bb8ffe"
      },
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')\n",
        "print(vocab)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65 unique characters\n",
            "['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7og2-YWUviB"
      },
      "source": [
        "# **Process the text**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Y8mKJWTU6G8"
      },
      "source": [
        "## Vectorize the text\n",
        "Before training, you need to convert the strings to a numerical representation.\n",
        "\n",
        "The **preprocessing.StringLookup** layer can convert each character into a numeric \n",
        "ID. It just needs the text to be split into tokens first."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ou6fQv-UV8B"
      },
      "source": [
        "ids_from_chars = preprocessing.StringLookup(\n",
        "    vocabulary=list(vocab), mask_token=None)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05bfTe7bXn89"
      },
      "source": [
        "### **Example**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJo51zWQXEoF",
        "outputId": "f1301272-1a8a-4298-b35e-f733cfd41bb6"
      },
      "source": [
        "# Example\n",
        "temp_string_list = ['a','b','k','Q','R']\n",
        "ids = ids_from_chars(temp_string_list)\n",
        "print(ids)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([40 41 50 30 31], shape=(5,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDvvJtH0Xaoq"
      },
      "source": [
        "You can **tf.strings.reduce_join** to join the characters back into strings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQUq8OqvVhKI"
      },
      "source": [
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndAFTHgYX0cO",
        "outputId": "92d2904d-1f03-4075-c3e2-73d9389f2b5f"
      },
      "source": [
        "print(text_from_ids(ids))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'abkQR', shape=(), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frzCKUh3Wbh9"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Since the goal is to generate text, it will also be important to invert this representation and recover human-readable strings from it. For this you can use **preprocessing.StringLookup(..., invert=True)**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqJFEp8kVgXP"
      },
      "source": [
        "chars_from_ids = tf.keras.layers.experimental.preprocessing.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZ3MNcWuYLDI"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "The input to the model will be a sequence of characters, and you train the model to predict the output i.e. the following character at each time step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbvz_TCIbmx0"
      },
      "source": [
        "### **Create training examples and targets**\n",
        "\n",
        "Next divide the text into example sequences. Each input sequence will contain seq_length characters from the text.\n",
        "\n",
        "For each input sequence, the corresponding targets contain the same length of text, except shifted one character to the right.\n",
        "\n",
        "So break the text into chunks of **seq_length+1**. For example, say seq_length is 4 and our text is \"Hello\". The input sequence would be \"Hell\", and the target sequence \"ello\".\n",
        "\n",
        "To do this first use the **tf.data.Dataset.from_tensor_slices** function to convert the text vector into a stream of character indices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ySz3AeDW8rA",
        "outputId": "f34f711f-63cb-40ed-b645-614b9644de09"
      },
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8ThXJ5Ab2Jx"
      },
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTTBcvl-b7pS",
        "outputId": "23df4c77-4202-46ed-eb26-328d1c08716b"
      },
      "source": [
        "for ids in ids_dataset.take(10):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n",
            " \n",
            "C\n",
            "i\n",
            "t\n",
            "i\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ENvnAEccAuw"
      },
      "source": [
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//(seq_length+1)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cD_Vy6N9ckwr"
      },
      "source": [
        "The **batch** method lets you easily convert these individual characters to sequences of the desired size.\n",
        "\n",
        "\n",
        "Example:\n",
        "```\n",
        ">>> dataset = tf.data.Dataset.range(8)\n",
        ">>> dataset = dataset.batch(3)\n",
        ">>> list(dataset.as_numpy_iterator())\n",
        "\n",
        "[array([0, 1, 2]), array([3, 4, 5]), array([6, 7])]\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHex36Y5cQju",
        "outputId": "e26007d9-0635-46ac-92ec-e92cbec8f900"
      },
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
            " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
            " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
            " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
            " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n",
            " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n",
            " b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n",
            " b'o' b'u' b' '], shape=(101,), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxcPCjWfcyFQ"
      },
      "source": [
        "It's easier to see what this is doing if you join the tokens back into strings:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Pg7-ZTNccVI",
        "outputId": "8dd37fd2-282b-4cae-c628-d75dede893f2"
      },
      "source": [
        "for seq in sequences.take(5):\n",
        "  print(text_from_ids(seq).numpy())"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
            "b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
            "b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
            "b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
            "b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eOdanMaeCOz"
      },
      "source": [
        "For training you'll need a dataset of **(input, label)** pairs. Where input and label are sequences. At each time step the input is the current character and the label is the next character.\n",
        "\n",
        "Here's a function that takes a sequence as input, duplicates, and shifts it to align the input and label for each timestep:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utx0Fx2Ac0Hk"
      },
      "source": [
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1] # Tensorflo\n",
        "    target_text = sequence[1:] # ensorflow\n",
        "    return input_text, target_text"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQ5C-GnjeZsq",
        "outputId": "cd4dcf22-3cd8-400f-e40e-d4e1b8e6221b"
      },
      "source": [
        "# Example\n",
        "split_input_target(list(\"Tensorflow\"))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRQogLDjeauM"
      },
      "source": [
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-GQ5Qd6hASl",
        "outputId": "7eef4d9e-018e-47e8-a611-2328077a6499"
      },
      "source": [
        "for input_example, target_example in dataset.take(2):\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy())"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "Target: b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
            "Input : b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you '\n",
            "Target: b're all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wZpGDYjyVOV"
      },
      "source": [
        "### **Create training batches**\n",
        "You used **tf.data** to split the text into manageable sequences. But before feeding this data into the model, you need to shuffle the data and pack it into batches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLzzyQrBiq5w",
        "outputId": "1f5f0d73-cefb-467c-b762-9c30b86d9c4b"
      },
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtecBP5Fy1Vt"
      },
      "source": [
        "# **Build The Model**\n",
        "\n",
        "This model has three layers:\n",
        "\n",
        "\n",
        "\n",
        "*   **tf.keras.layers.Embedding**: The input layer. A trainable lookup table that will map each character-ID to a vector with **embedding_dim** dimensions;\n",
        "\n",
        "*   **tf.keras.layers.GRU**: A type of RNN with size **units=rnn_units** (You can also use an LSTM layer here.)\n",
        "\n",
        "*   **tf.keras.layers.Dense**: The output layer, with **vocab_size** outputs. It outputs one logit for each character in the vocabulary. These are the log-likelihood of each character according to the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGjACSMXykMs"
      },
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCFPvU7Azgus"
      },
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4K6o0C4A_lg"
      },
      "source": [
        "# model = Sequential()\n",
        "# model.add(Embedding(vocab_size, embedding_dim)\n",
        "# model.add(LSTM(200))\n",
        "# model.add(Dense(vocab_size)\n",
        "# adam = Adam(lr=0.01)\n",
        "# model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "# # earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto')"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZuJXCmVznrF"
      },
      "source": [
        "model = MyModel(\n",
        "    # Be sure the vocabulary size matches the `StringLookup` layers.\n",
        "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baJDy84_0iuq"
      },
      "source": [
        "### **Try the model**\n",
        "\n",
        "Now run the model to see that it behaves as expected.\n",
        "\n",
        "First check the shape of the output:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnztrPkPzqJa",
        "outputId": "c155cbab-bd4e-4335-f0e8-25bf83c503ca"
      },
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 66) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoRJU1Fd0qWK",
        "outputId": "996243b9-33f9-4a7e-fc5b-bf7383431c0f"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        multiple                  16896     \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    multiple                  3938304   \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              multiple                  67650     \n",
            "=================================================================\n",
            "Total params: 4,022,850\n",
            "Trainable params: 4,022,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "id": "CFDVGIEG09Tm",
        "outputId": "72885a93-3882-4787-bf61-71dc4511b38a"
      },
      "source": [
        "tf.keras.utils.plot_model(\n",
        "    model\n",
        ")"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHQAAAA8CAIAAAA48wlxAAAABmJLR0QA/wD/AP+gvaeTAAAFZUlEQVR4nO2bS0gbWxiA/xNNMk5ik+AjSo2tiI+KCNV2IbSbSqEUBK2WBlcGI9UuXLQ+UEuE1oXgc2MrVQs+SiIGEak7XZRCJSqoEcGYEvBRFFowTcxIqnG6GG4Yb3PrKyd64/l2/3n9P19mTk4mCWJZFgh4EJx3AcEMkYsRIhcjRC5GQvnB1NRUW1vbeZUSBDx//jw7O9sbHrpy19fXjUZjwEsKEoxG4/r6Or8l9M9Bw8PDgaonqEAI/auF7LkYIXIxQuRihMjFCJGLESIXI0QuRohcjBC5GCFyMULkYoTIxQiRixEiFyOXUa5Wqw0PD0cIzc/P/2VYS0tLdHQ0Qqirq+t0iS6j3J6enu7u7iOHVVZWfvny5SyJLqPcgHFJ5f75rQEOTiy3o6NDIpEIBIKsrCylUikUCiUSSWZm5t27d1UqFUVRcrm8urqaG6zVahFCCKHExMS5uTkA0Gg0NE3LZLKxsTE/JgIAlmXb2tpu3LghFosVCkVeXt7y8jK/t7m5OSUlRSwWy2Syqqoqfi6Px6PT6eLj48PCwjIyMoaGhk6qxTcsD25R9igaGhoAwGQyuVyuHz9+PHjwAADGx8e/f//ucrkqKioAYH5+nhtcUFAQEhLy7ds37/SioqKxsbEjs5w0kU6nE4lEAwMDdrvdbDZnZmZGRkZubW1xvfX19Qih1tbW7e1thmE6OzsBYG5ujuutrKwUi8VGo3F7e7uurk4gEMzMzLAsa7VaAeDt27fHqRYAhoaGDrXwgxPJdTqdXNjX1wcAi4uLXDg9PQ0ABoOBCycmJgCgsbGRC3/+/JmUlLS/v3+cco+fiGEYqVSqVqu9c7neV69ecb00Td+/f9/bq9frvXJ3d3dpmvbOZRhGLBY/e/aMPbNcP+y5IpEIAPb397lQKBQCwN7eHhfeu3cvOTn5/fv3XHqDwaBWq0NCQvybaGlpaWdn59atW97Bt2/fFolEJpMJAL5+/cowTE5Ojs9lLRYLwzDp6elcGBYWFhMTw99STg32NzSEUFlZmc1mm5ycBID+/v6SkhK/Z7Hb7QAglUr5jXK53Ol0AsDGxgYAREVF+ZzrcrkA4OXLl+gfVldXGYY5e1WBOC0UFxdTFNXT02OxWK5cuXLt2jW/p5DL5QDAqfRit9vj4uIAgKIoAHC73T7nctLb29v5d/TU1NTZqwqEXIVC8eTJk9HR0ZaWltLSUhwp0tPTpVLp7Oyst8VkMv369SsrK4vrFQgEnz598jmXO3v8/dPa6QjQObe8vNztdn/8+DE3NxfH+hRFvXjxYmRkZHBw0OFwLC4ulpeXx8bGPn36FACioqIKCgqMRmNvb6/D4TCbze/evePP1Wg0er3+zZs3DofD4/FsbGxsbm76oSz+vXCc00JHRwdN0wBw/fr1z58/NzU1yWQyAFAqlR8+fDAYDEqlEgAUCoVer+dPvHnzZm1t7XHedk+X6ODgoLm5OSkpSSgUKhSK/Px8i8XiXc3pdGq12oiICKlUeufOHZ1OBwBxcXELCwssy7rd7pqamvj4+NDQUO6VWFpaam1t5VJIJJJHjx4dWTD45Sh2Oh4+fGiz2TAtfhH4Uy7ebcF7IDObzRRFJSQkYE130cArt6amxmq1rqysaDSa169f87uWl5fRf6NWq7EWFhh8/ITUj9A0nZqaevXq1c7OzrS0NH5XamoqG+x/JMJ75TY2Nno8nrW1NUyHhAvOJX3kGBiIXIwQuRghcjFC5GKEyMUIkYsRIhcjRC5GiFyMELkYIXIxQuRixMcjx8ePHwe+jqDk0JWrUqkKCwvPq5T/O4WFhSqVit+Cgv6J9TlC9lyMELkYIXIxQuRi5DdEQF0z6zrvnQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZH_d_Rew2Xqs"
      },
      "source": [
        "# **Train the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojCPmIKW1V1j"
      },
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMvhRi-02uJG",
        "outputId": "8beba962-5089-4341-e5c7-b5c189f3086c"
      },
      "source": [
        "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
        "mean_loss = example_batch_loss.numpy().mean()\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", mean_loss)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (64, 100, 66)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         4.190166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONtZ1NuD2vDj",
        "outputId": "fa3cf5f4-4980-47c7-c031-30b723ed49fe"
      },
      "source": [
        "tf.exp(mean_loss).numpy()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "66.03375"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNlB9dK_3Bqk",
        "outputId": "458b2564-42ba-48c8-96f6-0c70d27affed"
      },
      "source": [
        "adam = Adam(lr=0.01) # added\n",
        "model.compile(optimizer= adam, loss=loss)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQKEZ-LK3mDM"
      },
      "source": [
        "### Configure **checkpoints**\n",
        "Use a **tf.keras.callbacks.ModelCheckpoint** to ensure that checkpoints are saved during training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsI1NSE33i23"
      },
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = '/content/training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlL02iXP3r7e"
      },
      "source": [
        "EPOCHS = 30"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LX0EWyMD350f"
      },
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpycWF9W4p9D"
      },
      "source": [
        "# **Generate text**\n",
        "\n",
        "The simplest way to generate text with this model is to run it in a loop, and keep track of the model's internal state as you execute it.\n",
        "\n",
        "![text_generation_sampling.png](data:image/png;base64,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)\n",
        "\n",
        "Each time you call the model you pass in some text and an internal state. The model returns a prediction for the next character and its new state. Pass the prediction and state back in to continue generating text.\n",
        "\n",
        "The following makes a single step prediction:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFe_2WVf37Es"
      },
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMtz91ru5Au7"
      },
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oaEH0Ko5JO-",
        "outputId": "a6610d1c-92d5-4e19-8d83-3c40034d284e"
      },
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['A rose for thee'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A rose for thee; I conjure thee.\n",
            "How canst thou swear by the garden on the boace?\n",
            "Seeming to your cousin! hath brief themselves?\n",
            "Why, then, since you bight what after good, good\n",
            "But pay no rump: the rest shall count his king:\n",
            "But where our safer ire, whom thou shouldst be the\n",
            "seconver to the Capitol.\n",
            "\n",
            "KING RICHARD II:\n",
            "Well, Peace be that of true about your\n",
            "equals; and all the provost, cousin, 'Pamen and fruit the infurment\n",
            "And smother'd for virtuous danger and our possession\n",
            "Than my haste way.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Pray you, le, this; I hold it thee.\n",
            "\n",
            "KING LEWIS XI:\n",
            "Then, Poor bride, reasy it him forth from thence.\n",
            "Save your great conclusion, baids to show a stuty of\n",
            "one fourer than the is the manner,\n",
            "Commanded to deliver us their neither grieve\n",
            "The langus's action and woman living beht,\n",
            "And, Angelo:--\n",
            "\n",
            "COMINIUS:\n",
            "We must toing with many throats\n",
            "to the contract and suffer'd up.\n",
            "\n",
            "DUCHESS OF YORK:\n",
            "A gentleman on my mother, tear it is thy life\n",
            "Shalt be the vigour lies with honey work,\n",
            "As if the world I heard  \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 3.9821577072143555\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kl3SX7Hq8ehh"
      },
      "source": [
        "# **Export the generator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZndXcjB7eOo",
        "outputId": "bfd521ce-ce48-440f-f170-436e25dfe047"
      },
      "source": [
        "tf.saved_model.save(one_step_model, 'one_step')\n",
        "one_step_reloaded = tf.saved_model.load('one_step')"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x7ff780370e50>, because it is not built.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: one_step/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: one_step/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O61RsYo28iRy",
        "outputId": "0dd75a01-6250-471b-926e-ec6db6958958"
      },
      "source": [
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(100):\n",
        "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO:\n",
            "Tell me of thousand, Kate, an end of mercy!\n",
            "\n",
            "NORFOLK:\n",
            "Ay, so I did request you.\n",
            "\n",
            "LEONTES:\n",
            "We'll he \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIYe61yD8u7P"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}